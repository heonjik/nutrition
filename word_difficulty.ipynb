{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Word  Length  Freq_HAL  Log_Freq_HAL  I_Mean_RT  I_Zscore    I_SD   Obs  \\\n",
      "0      a       1  10610626         16.18     798.92     -0.01  333.85  24.0   \n",
      "1    aah       3       222          5.40     816.43      0.21  186.03  21.0   \n",
      "2  Aaron       5     10806          9.29     736.06     -0.11  289.01  32.0   \n",
      "3  aback       5       387          5.96     796.27      0.11  171.61  15.0   \n",
      "\n",
      "   I_Mean_Accuracy  \n",
      "0             0.73  \n",
      "1             0.62  \n",
      "2             0.97  \n",
      "3             0.45  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('WordDifficulty.csv')\n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What each columns represents\n",
    "According to _Word Difficulty Prediction Using Convolutional Neural Networks_ (who provided the dataset),\n",
    "* **I_Zscore**: the mean lexical decision latency for each word - directly relates to the difficulty of a word.\n",
    "    * 0 for \"simple\" & 1 for \"difficult\" (binary classification).\n",
    "    * If I_Zscore <= 0, the class is 0.\n",
    "    * If I_Zscore > 0, the class is 1.\n",
    "* **Freq_HAL**: Hyperspace Analogue to language frequency norms based on the HAL corpus of 131 million words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Log_Freq_HAL</th>\n",
       "      <th>I_Mean_RT</th>\n",
       "      <th>I_Zscore</th>\n",
       "      <th>I_SD</th>\n",
       "      <th>Obs</th>\n",
       "      <th>I_Mean_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9844</th>\n",
       "      <td>diacritical</td>\n",
       "      <td>11</td>\n",
       "      <td>162</td>\n",
       "      <td>5.09</td>\n",
       "      <td>1458.75</td>\n",
       "      <td>2.51</td>\n",
       "      <td>421.41</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Word  Length  Freq_HAL  Log_Freq_HAL  I_Mean_RT  I_Zscore  \\\n",
       "9844  diacritical      11       162          5.09    1458.75      2.51   \n",
       "\n",
       "        I_SD  Obs  I_Mean_Accuracy  \n",
       "9844  421.41  4.0             0.17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the word that has the highest I_Zscore.\n",
    "df[df['I_Zscore']==df['I_Zscore'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Log_Freq_HAL</th>\n",
       "      <th>I_Mean_RT</th>\n",
       "      <th>I_Zscore</th>\n",
       "      <th>I_SD</th>\n",
       "      <th>Obs</th>\n",
       "      <th>I_Mean_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13553</th>\n",
       "      <td>filmdom</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>509.67</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>135.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Length  Freq_HAL  Log_Freq_HAL  I_Mean_RT  I_Zscore   I_SD  \\\n",
       "13553  filmdom       7         3           1.1     509.67     -1.03  135.5   \n",
       "\n",
       "       Obs  I_Mean_Accuracy  \n",
       "13553  3.0             0.09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the word that has the lowest I_Zscore.\n",
    "df[df['I_Zscore']==df['I_Zscore'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in class 0: 22630\n",
      "Number of words in class 1: 17838\n"
     ]
    }
   ],
   "source": [
    "# Categorize into \"simple\" and \"difficult\" words.\n",
    "simple_word_list = df.loc[df['I_Zscore'] <= 0]\n",
    "diff_word_list = df.loc[df['I_Zscore'] > 0]\n",
    "print(f\"Number of words in class 0: {len(simple_word_list)}\")\n",
    "print(f\"Number of words in class 1: {len(diff_word_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyunjikim/anaconda3/envs/simple-text/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>Log_Freq_HAL</th>\n",
       "      <th>I_Mean_RT</th>\n",
       "      <th>I_Zscore</th>\n",
       "      <th>I_SD</th>\n",
       "      <th>Obs</th>\n",
       "      <th>I_Mean_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>Alice</td>\n",
       "      <td>5</td>\n",
       "      <td>5711</td>\n",
       "      <td>8.65</td>\n",
       "      <td>646.64</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>173.54</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13574</th>\n",
       "      <td>finality</td>\n",
       "      <td>8</td>\n",
       "      <td>137</td>\n",
       "      <td>4.92</td>\n",
       "      <td>683.08</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>191.29</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32273</th>\n",
       "      <td>showery</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.69</td>\n",
       "      <td>782.26</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>329.51</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13462</th>\n",
       "      <td>fickle</td>\n",
       "      <td>6</td>\n",
       "      <td>291</td>\n",
       "      <td>5.67</td>\n",
       "      <td>735.46</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>204.37</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Length  Freq_HAL  Log_Freq_HAL  I_Mean_RT  I_Zscore    I_SD  \\\n",
       "930       Alice       5      5711          8.65     646.64     -0.46  173.54   \n",
       "13574  finality       8       137          4.92     683.08     -0.18  191.29   \n",
       "32273   showery       7         2          0.69     782.26     -0.01  329.51   \n",
       "13462    fickle       6       291          5.67     735.46     -0.21  204.37   \n",
       "\n",
       "        Obs  I_Mean_Accuracy  \n",
       "930    33.0             0.97  \n",
       "13574  25.0             0.78  \n",
       "32273  27.0             0.82  \n",
       "13462  26.0             0.81  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicies = np.arange(len(df))\n",
    "indices_train, indices_test = train_test_split(indicies, test_size=0.3, random_state=42)\n",
    "df_train = df.iloc[indices_train]\n",
    "df_test = df.iloc[indices_test]\n",
    "df_train.head(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-text",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
